_target_: models.mamba.MambaLMHeadModel
tag: mamba10M
d_model: 384
n_layer: 6
vocab_size: ${eval:'${..data.n_obs} + 1'} 
d_intermediate: 640
ssm_cfg:
  layer: Mamba2 
  d_state: 128
  d_conv: 4
  headdim: 32