batch_size: 512
val_split: 0.1
pretrained_id: uef49gwb # explicit_known
lr: 0.0001
loss: l2
train_schedule: cosine
diffusion_objective: pred_v
tag: known_large

model:
  n_embd: 512
  n_layers: 8
  n_heads: 8
  dropout: 0.0
  scale_shift: True
  seq_conditional: True
  cond_modulation: True
  seq_conditional_dim: null
  seq_unconditional_prob: 0.0
  self_condition: False
  cond_encoder_kwargs:
    n_layers: 3
    n_heads: 8
    vocab_size: null
    
dataset:
  _target_: data.diffusion.KnownEncoderDiffusionDatasetConfig
  context_length: [1, 30]
  pretrained_embedding: True
  pretrained_embedding_id: q4bv9oa7 # gpt5M
  pretrained_encoder_id: uef49gwb