batch_size: 512
val_split: 0.1
pretrained_id: 3xykj5li # gru5M
lr: 0.0001
loss: l2
train_schedule: cosine
diffusion_objective: pred_v

model:
  n_embd: 512
  n_layers: 8
  n_heads: 8
  dropout: 0.0
  scale_shift: True
  seq_conditional: True
  cond_modulation: True
  cond_encoder_kwargs:
    n_layers: 3
    n_heads: 8
    vocab_size: null
  
dataset:
  _target_: data.diffusion.GRUDiffusionDatasetConfig
  context_length: [200, 200]
  suffix_size: [1,30]
  pretrained_embedding: True
  pretrained_embedding_id: 3xykj5li 
  cond_hidden: False