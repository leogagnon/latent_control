batch_size: 512
val_split: 0.1
pretrained_id: 39sfv9fz # explicit_gpt10M
lr: 0.0001
loss: l2
train_schedule: cosine
diffusion_objective: pred_v

model:
  n_embd: 512
  n_layers: 8
  n_heads: 8
  dropout: 0.0
  scale_shift: True
  seq_conditional: True
  seq_unconditional_prob: 0.0
  cond_modulation: True
  self_condition: False
  cond_encoder_kwargs: null
  
dataset:
  _target_: data.diffusion.ExplicitDiffusionDatasetConfig
  context_length: [190, 190]
  suffix_size: [1,30]
  pretrained_embedding: False
  cond_hidden: True