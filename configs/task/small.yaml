data : 
  n_latents: 10
  n_states: 20
  n_overlap: 1
  min_active_latents: 4
  max_active_latents: 8
  context_length: 50

model:
  block_size: 200
  vocab_size: 21 
  n_layer: 4
  n_head: 4
  n_embd: 64
  dropout: 0.1
  bias: False

val_ratio: 0.1
batch_size: 256
lr: 1e-3