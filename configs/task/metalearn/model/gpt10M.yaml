tag: gpt10M
decoder:
  _target_: models.decoder.TransformerDecoder
  max_seq_len: 500
  num_tokens : null 
  n_layer: 6
  n_head: 8
  n_embd: 384
  positional_encodings: True