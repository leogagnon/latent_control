sweep_id: smallseqs_${now:%Y-%m-%d}-${now:%H-%M-%S}

task/data: small
task/model: mamba, gpt_medium
task.data.context_length: '[50,50], [1,50]'
task.data.block_diag_mask: False
seed: 12
model_checkpoint.save_top_k: 1

max_steps: 10000000000000000 # won't reach the max, seen_tokens is our stopping condition
max_tokens: 1000000000 # 1B