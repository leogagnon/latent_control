sweep_id: pooled_trainable${now:%Y-%m-%d}-${now:%H-%M-%S}

task/metalearn: base

task/metalearn/data: small
task/metalearn/model: ctx/pooled
task.metalearn.model.encoder.pretrained_id: fdz6s37e, 6enbwdmh # gru[ctx], gru
task.metalearn.model.encoder.trainable: True, False
task.metalearn.model.encoder.context_is_prefix: False
task.metalearn.model.encoder.normalize: True
task.metalearn.model.encoder.layernorm: True
task.metalearn.model.encoder.pool_last_n: 50
task.metalearn.model.encoder.out_dim: 256

seed: 15

model_checkpoint: base
max_steps: 50000 # won't reach the max, max_tokens is our stopping condition