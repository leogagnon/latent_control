sweep_id: base_bottleneck_small${now:%Y-%m-%d}-${now:%H-%M-%S}

task/metalearn: base

task/metalearn/data: small
task/metalearn/model: ctx/gpt_bn_0, ctx/gpt_bn_1, ctx/gpt_bn_2
task.metalearn.model.encoder.normalize: False
seed: 15

model_checkpoint: base
max_steps: 50000 # won't reach the max, max_tokens is our stopping condition