{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/l/leo.gagnon/latent_control/venv/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/home/mila/l/leo.gagnon/latent_control/venv/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/home/mila/l/leo.gagnon/latent_control/venv/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "/home/mila/l/leo.gagnon/latent_control/venv/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "/home/mila/l/leo.gagnon/latent_control/venv/lib/python3.10/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/mila/l/leo.gagnon/latent_control')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lightning_modules.diffusion_prior import DiffusionPriorTask\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from data.diffusion import KnownLatentDiffusionDataset\n",
    "from torch2jax import j2t, t2j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset : (11288/1000)\n",
      "Loaded checkpoing : last.ckpt\n",
      "Loaded checkpoing : last.ckpt\n"
     ]
    }
   ],
   "source": [
    "task = DiffusionPriorTask('61xaxbsl')\n",
    "task.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.train_data.dataset \n",
    "dataset: KnownLatentDiffusionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/l/leo.gagnon/latent_control/data/hmm.py:585: FutureWarning: None encountered in jnp.array(); this is currently treated as NaN. In the future this will result in an error.\n",
      "  intv_envs = jnp.array(intv_envs)\n"
     ]
    }
   ],
   "source": [
    "latent, cond_input_ids, cond_tokens, cond_ignore_mask = dataset[3121].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_mask = torch.BoolTensor([True]*200)[None].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.diffusion_prior.cfg.sampler = 'dpmpp' # ddpm, dpmpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9261fba92643c4a526bd8f12dbefce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_t = task.diffusion_prior.sample(100, cond_tokens=cond_tokens, cond_mask=cond_mask, cls_free_guidance=1.0)\n",
    "#z_t = task.diffusion_prior.unnormalize_latent(z_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_t = task.diffusion_prior.unnormalize_latent(z_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 2.]),\n",
       " tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 2.]),\n",
       " tensor([1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 2.]),\n",
       " tensor([3., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 2.]),\n",
       " tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 2.]),\n",
       " tensor([3., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([2., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 2.]),\n",
       " tensor([3., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.]),\n",
       " tensor([2., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 2.]),\n",
       " tensor([2., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 2.]),\n",
       " tensor([3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([2., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 2.]),\n",
       " tensor([1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 2.]),\n",
       " tensor([0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 2.]),\n",
       " tensor([1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([2., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 2.]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]),\n",
       " tensor([3., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.]),\n",
       " tensor([0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 2.]),\n",
       " tensor([3., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 2.]),\n",
       " tensor([1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 2.]),\n",
       " tensor([3., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 2.]),\n",
       " tensor([1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 2.]),\n",
       " tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 2.]),\n",
       " tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 2.]),\n",
       " tensor([3., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 2.]),\n",
       " tensor([1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 2.]),\n",
       " tensor([1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 2.]),\n",
       " tensor([2., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.]),\n",
       " tensor([3., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1.]),\n",
       " tensor([1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 2.]),\n",
       " tensor([2., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 2.]),\n",
       " tensor([3., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " tensor([2., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 2.]),\n",
       " tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 2.]),\n",
       " tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 2.]),\n",
       " tensor([1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 2.]),\n",
       " tensor([0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 2.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 2.]),\n",
       " tensor([3., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 2.]),\n",
       " tensor([3., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 2.]),\n",
       " tensor([1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 2.])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.Tensor([(latent_embds.weight @ z_t[i].T).argmax() for latent_embds in task.base_task.model.encoder.latent_embedding]) for i in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5561e+00,  7.4856e-01,  4.1153e+00, -2.4731e+00, -1.4466e+00,\n",
       "          -1.2991e+00,  1.7986e+00, -4.4539e+00,  4.6276e+00, -1.2840e+00,\n",
       "           2.8628e+00, -3.8792e+00, -5.9071e-01, -3.0843e+00, -1.9485e+00,\n",
       "          -5.2641e+00, -2.8646e+00, -7.0337e-01, -1.9427e+00, -4.3665e-02,\n",
       "          -3.2926e+00,  7.2712e+00, -2.4647e+00, -3.3398e-01, -9.0019e-01,\n",
       "           2.2383e+00, -1.4827e+00, -5.2373e+00, -1.0177e+00,  8.3677e-01,\n",
       "           1.1302e+00,  2.2745e-01, -8.5907e-01, -9.6679e-02,  1.4911e+00,\n",
       "          -2.5468e+00, -2.5649e-01,  1.3726e+00,  1.0484e+00,  5.3324e+00,\n",
       "           2.2521e+00, -2.0496e-01, -2.1855e+00,  9.1902e-01,  1.8415e+00,\n",
       "          -8.1387e-02, -3.7777e-01, -5.3471e+00,  1.3217e+00, -1.6922e+00,\n",
       "          -8.1620e-02,  1.1876e+00, -3.2295e+00,  4.5442e-01, -2.4309e+00,\n",
       "          -2.0893e+00, -1.1472e-01,  7.5290e-01, -6.6094e-01, -5.4295e+00,\n",
       "          -1.5896e+00, -8.8771e-01,  1.8211e+00, -2.7817e-01, -3.2782e+00,\n",
       "           4.9800e-01,  1.1014e+00,  4.9614e-01, -1.5847e+00, -1.3923e+00,\n",
       "           3.9349e-01,  4.0283e+00, -1.2896e+00,  8.2044e-01, -4.9412e+00,\n",
       "          -2.9798e+00,  2.4609e+00,  4.4731e-01,  6.6858e-02,  1.1694e+00,\n",
       "           8.4559e+00, -1.1778e+00,  1.4795e+00,  3.8690e+00,  1.4834e-01,\n",
       "          -1.7889e+00,  6.6070e-01,  5.2280e+00,  4.8283e+00, -1.7380e+00,\n",
       "          -2.1470e+00, -1.0541e+00,  2.3826e+00,  4.4132e+00, -3.9041e-01,\n",
       "          -2.2352e+00,  5.2144e-01,  4.3910e-01, -2.1138e+00,  8.8873e-03,\n",
       "          -1.5773e+00,  2.8970e+00, -1.4893e+00, -2.3291e+00, -2.8907e+00,\n",
       "          -4.3428e-01, -4.1267e+00, -3.6497e+00,  1.5658e+00, -9.8448e+00,\n",
       "          -3.9897e+00,  5.3987e+00, -1.6187e-01, -1.4816e+00, -2.0412e+00,\n",
       "          -3.1563e-01, -3.2272e+00, -6.4355e+00,  1.0665e+00, -3.3088e+00,\n",
       "           2.8683e-01,  5.1478e-01,  6.6100e-01, -7.9201e-01,  4.3066e+00,\n",
       "          -1.2169e+00,  1.5547e+00,  6.4082e+00, -2.3957e+01,  8.9560e-01,\n",
       "          -2.3299e-01,  1.7468e+00, -4.7082e-01, -3.5549e+00, -3.3263e+00,\n",
       "           9.1778e+00,  8.6840e-02, -7.2583e-01, -1.4043e+00, -2.2131e+00,\n",
       "          -1.1296e-01, -1.6648e+00,  7.5224e-01,  2.9480e+00, -3.5218e+00,\n",
       "           5.4103e+00, -5.3860e+00, -5.2398e+00,  2.8314e+00, -3.5195e-01,\n",
       "          -6.6004e-01, -2.5754e-01,  2.3606e-01,  1.6148e+00, -2.0540e+00,\n",
       "          -1.1242e+00, -2.3692e+00,  4.2684e+00,  6.6911e-01, -3.5764e-01,\n",
       "          -5.9883e-01, -1.4470e+00,  1.9006e+00,  2.6367e+00, -2.6114e+00,\n",
       "           1.4096e+00,  1.3677e+00,  2.2680e-01,  1.6606e+00,  2.3720e-01,\n",
       "          -3.0345e+00, -1.3401e+00, -6.9170e+00, -2.5289e+00,  1.7668e+00,\n",
       "           1.1186e+00,  2.3062e+00, -5.0444e-01,  2.4983e+00,  2.2246e+00,\n",
       "           1.8526e+00,  2.2397e+00,  1.3279e+00,  2.7607e+00,  1.2606e+00,\n",
       "           5.2311e-02,  1.4048e+00, -5.6318e-01, -1.6763e+00,  3.1107e+00,\n",
       "          -4.6491e-01,  1.3422e+00,  3.0766e-01, -1.2541e-01, -2.5993e+00,\n",
       "          -9.2582e-02,  4.9404e+00, -7.1534e-01,  5.5013e-01, -2.1276e+00,\n",
       "           1.3850e+00,  4.3859e+00,  4.4319e+00,  6.0058e-01,  3.0909e+00,\n",
       "           1.3668e+00,  3.4915e+00,  1.0264e+00,  2.4329e+00, -2.6230e-02,\n",
       "          -2.0158e+00,  4.3698e+00,  5.7681e+00,  1.5743e+00,  2.9844e+00,\n",
       "           3.0626e-01, -2.7459e-01,  2.7682e+00, -1.9240e+00,  1.2568e+00,\n",
       "          -2.3043e+00,  2.1754e+00,  9.3554e-01,  5.3593e+00,  2.7081e+00,\n",
       "          -5.5542e+00, -3.0383e+00,  2.9777e+00,  7.3845e-01,  9.3550e+00,\n",
       "           5.3568e+00, -3.6365e+00,  3.4764e+00,  2.5383e+00, -9.5999e-01,\n",
       "           1.8518e+01, -5.6384e+00, -4.4152e+00, -2.3272e+00, -7.8096e-01,\n",
       "           3.0694e+00, -1.7183e+00, -7.6443e-02,  3.5245e+00,  9.5065e-01,\n",
       "          -1.3140e+00, -4.0535e+00,  5.7973e-01,  1.7668e+00, -3.6576e+00,\n",
       "           7.8964e-01,  4.5311e+00,  8.6730e-01,  3.7166e+00,  2.3201e+00,\n",
       "           2.0170e+00]]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_latents = j2t(task.base_task.full_data.index_to_latent)[0].to(torch.long).cuda()[None]\n",
    "env_latents = task.base_task.model.encoder(true_latents=env_latents)\n",
    "env_latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 179.3701],\n",
       "        [-104.5878]], device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.base_task.model.encoder.latent_embedding[3].weight @ z_t[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[189.8581],\n",
       "        [ -6.5179]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.base_task.model.encoder.latent_embedding[1].weight @ z_t[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.base_task.full_data.index_to_latent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([2., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 2.]),\n",
       " tensor([2., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 2.]),\n",
       " tensor([3., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([3., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([3., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 2.]),\n",
       " tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([3., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.]),\n",
       " tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 2.]),\n",
       " tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.Tensor([(latent_embds.weight @ z_t[i].T).argmax() for latent_embds in task.base_task.model.encoder.latent_embedding]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
