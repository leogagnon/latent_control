batch_size: 256
val_split: 0.1
loss: l2
pretrained_id: ekly943l
lr: 0.0001
dataset:
  _target_: data.diffusion.KnownLatentDiffusionDatasetConfig
  context_length: [1, 200]
diffusion:
  latent_shape: [1,256]
  sampling_schedule: null
  sampling_timesteps: 250
  seq_conditional: True
  seq_conditional_dim: 256
  seq_unconditional_prob: 0.1
  class_conditional: False
  num_classes: 0
  class_unconditional_prob: 0.0
  self_condition: True
  train_prob_self_cond: 0.5
  train_schedule: cosine
  objective: pred_x0
  scale: 1.0
  sampler: ddpm
  l2_normalize: False
  normalize_latent: True
  # Transformer-specific config
  n_embd: 256
  n_layers: 4
  n_heads: 6
  scale_shift: True
  num_dense_connections: 2
  dropout: 0.0