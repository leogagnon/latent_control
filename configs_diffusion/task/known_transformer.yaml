batch_size: 512
val_split: 0.1
loss: l1
pretrained_id: ekly943l
lr: 0.0001
lr_scheduler: True
dataset:
  _target_: data.diffusion.KnownLatentDiffusionDatasetConfig
  context_length: [200, 200]
diffusion:
  latent_shape: [1,256]
  sampling_schedule: null
  sampling_timesteps: 250
  seq_conditional: True
  seq_conditional_dim: 512
  seq_unconditional_prob: 0.1
  class_conditional: False
  num_classes: 0
  class_unconditional_prob: 0.1
  self_condition: True
  train_prob_self_cond: 0.5
  train_schedule: cosine
  objective: pred_v
  scale: 1.0
  sampler: ddpm
  normalize_latent: True
  # Transformer-specific config
  n_embd: 512
  n_layers: 6
  n_heads: 8
  scale_shift: True
  num_dense_connections: 3
  seq_conditional_vocab: 50
  dropout: 0.0